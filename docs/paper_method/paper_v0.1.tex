\documentclass[aps,pre,twocolumn,superscriptaddress]{revtex4-1}

\usepackage{amsfonts,amssymb,amsmath,latexsym,epsfig,wasysym} 
\usepackage[sort&compress]{natbib}
\usepackage{color}
\definecolor{bluecolor}{rgb}{0,0.,1.}
\def\Blue#1{{\color{bluecolor} #1}}
\definecolor{redcolor}{rgb}{.7,0.,0.}
\def\Red#1{{\color{redcolor} #1}}

\usepackage{bm}
\newcommand{\pp}{\bm{p}}
\newcommand{\qq}{\bm{q}}
\newcommand{\PP}{\bm{P}}

%\addtolength{\topmargin}{1.5cm}
% \usepackage{dblfloatfix}
%\baselineskip 25pt
\usepackage[utf8]{inputenc}

\begin{document}

\title{Using document emebddings to quantify the semantic relation between millions of scientific papers. }
% \title{Embedding techniques to create science maps of millions of individual publications}



\author{Jared Lorince} 
\affiliation{Northwestern Institute of Complex Systems, Northwestern University, Evanston Illinois 60208, USA}

\author{Diego F.M. Oliveira} 
\affiliation{Northwestern Institute of Complex Systems, Northwestern University, Evanston Illinois 60208, USA}
\affiliation{Department of Chemical and Biological Engineering, Northwestern University, Evanston Illinois 60208, USA}

\author{Martin Gerlach} 
\affiliation{Department of Chemical and Biological Engineering, Northwestern University, Evanston Illinois 60208, USA}

\author{Brian Uzzi}
\affiliation{Northwestern Institute of Complex Systems, Northwestern University, Evanston Illinois 60208, USA}

\begin{abstract}
% \begin{center}\today\end{center}
%
R
Embedding techniques are a promising tool.
Here, we show how these methods are useful.
We apply to 22M articles of web of science.
On the one hand we perform a systematic analsysi of the robustness of these models -- explain further: it is not just noise, and parameter settings.
More importantly, we investigate how resulting representation in feature space recovers relations on the level of 
i) fields, ii) journals, iii) authors, and iv) time.
This provides a spectrum of evidence that these models open new possibilities to uncover semantic relation between individual scientific papers on a scale of millions of documents.
We show an example of its usefulness -- not sure what exactly.


\end{abstract} 

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Introduction %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\showthe\columnwidth
\section{Introduction}
\label{sec.intro}
%
%%%mapping fields
Increasing volume of science -- we need automatic organization of the semantic content of millions of articles.
The aim is to obtain so-called maps of science~\cite{Shiffrin2004,Boyack2005,Rosvall2008}.

%%% Analysis of texts
While most approaches are based on the analysis of citations, the  digitization leads to a dramatic increase in the availability of the actual content or metaknowledge~\cite{Evans2011}, most importantly in the form of written text.
The latter sparked an interest in the large-scale analysis of texts from scientific publications revealing the organization and evolution of scientific fields~\cite{Boyack2011,Chavalarias2013,Kuhn2014,Vilhena2014,Dias2017}. (Perhaps discuss individual aspects in more detail).

%%% Level of individual papers - what is the problem
While most works approach this problem on an aggregate level of, e.g., journals or (pre-defined) fields, here, we want to quantify the semantic relation relation between individual articles.
The questions are:
Where are new articles added in the semantic space? 
How are new topics or regions in space populated?
Refer to the dense region of the research frontier?

%%% Novelty
We want to assess the novelty of an individual paper based on the language.
This is different to approaches based on citations~\cite{Uzzi2013} or clearly defined entities such as chemicals~\cite{Shi2015, Foster2015}.
Connect this idea to the concept of quantifying and tracing the research front~\cite{DeSollaPrice1963}

%%% How do we approach it 
Recently proposed embedding techniques based on neural networks~\cite{Goldberg2016} offer a promising tool to identify the underlying semantic structure in large collections of texts.
In contrast to established dimensionality reduction techniques such as Latent Dirichlet Allocation~\cite{Blei2003} using the bag-of-words assumption, embedding techniques take into account the stucture of words within texts.
This is especially promising for the largest databsase (in terms of coverage) such as Web of Science, where the textual information of an individual article is typically very sparse due to availability of only titles and abstracts.


%% What we do
Things we show:\\
We can easily scale to all 20M (+) papers with abstracts in the WoS.\\
The relation between articles captures meaningful semantic structure when measuring distances between articles form the same i) field, ii) authors, iii) journals, or iv) time.\\
This allows us to trace how individual articles populate and explore the semantic space.


\section{Document embeddings}
%
We apply so-called embedding techniques based on neural networks~\cite{Goldberg2016} which have been shown to provide a useful framework in revealing the underlying semantic structure contained in millions of documents.
Initially developed to represent relations between words, e.g. so-called word2vec~\cite{Mikolov2013}, these concepts have been extened to obtain an embedding of documents in a low-dimensional semantic space, e.g. doc2vec~\cite{Le2014}.
In contrast to other popular dimensionality reduction techniques such as Latent Semantic Indexing~\cite{Deerwester1990} or Latent Dirichlet Allocation~\cite{Blei2003}, which typically represent texts as bag-of-words, models based on embedding preserve (and thus take advantage of) the structure of words within individual texts.
In fact, it was shown in Ref.~\cite{Dai2015} that this leads to better results in quanitfying the similarity of texts.

How do the basics work in these techniques

\section{Qualitative illustration}
%
Relationship between words. Give some examples, e.g. the word entropy.
%
Give an example plot of the 2D-stuff to give qualitative impression of result - some fancy plot.
Note that this visualization only gives an approximate picture.
In Sec.~\ref{sec.viz.2d.limit} we show the correlation between the distances between two articles in the orginal space and the projected 2D-space.
As noted previously~\Red{CITE}, the 2D-projection only preserves local relationships between articles, i.e. larger distances are not representative of the true distance.

\section{Robustness Check}
%
Perform different robustness chekcs to see that these methods yield stable results.
\begin{itemize}
 \item Bootstrap/subsample the data (variation of results with repsect to perturbation from fluctuations in data)
 \item Run the same emebdding algorithm twice: This refers to what Lancichinetti et al (PRX,2015) describe as the reproducibility -- do we get the same result when simply re-running the algorithm?
 \item Vary the parameters of the embedding, e.g. number of dimensions or the context-window. Show that result is not dependent on a particular choice of parameter values
\end{itemize}


\section{Capturing Similarity / How meaningful are these models}
%
Our aim is to show that these models are meaningful, i.e. that they capture known semantic relations.
We investiagte 4 different cases.

We basically repeat the same analysis many times

1) Difference in distribution
\begin{itemize}
 \item measure a global distribution of distances
 \item measure distribution of items conditioned on their group-membership. group can be field, journal, time, author
 \item are the conditioned distributions different than the global dsitribution? (statistical significance, effect size in difference in mean, ...)
\end{itemize}

2) Probaiblity of sharing the label - looking at it from a different angle
\begin{itemize}
 \item how likely are two chosen articles to belong to the same group (field, journal, author, ...)
 \item pick two articles randomly and measure their distance
 \item calculate the probaiblity of sharing the group-membership conditioned on the distance
 \item ideally, we hope to see that the probability shows a decay as a function of the distance, i.e. measuring the distance allows us to make a prediction on certain properties of the papers.
\end{itemize}

3) Measuring density
\begin{itemize}
 \item not exaclty sure how to proceed here
\end{itemize}

\subsection{Fields}

\subsection{Journals}

\subsection{Authors}

\subsection{Time}

\section{Density-estimation}
%
We apply the document embedding to calculate how populated regions of the semantic space are.

This allows us to follow how the individual papers expand the frontier of knowledge.


\section{Discussion}
%
Alternative approach to finding a ``natural clustering'' (see the recent debate on how to evaluate results from different approaches~\cite{Glaser2017}) or one looks at the evolution or organization on an aggregate level of journals or fields.



\acknowledgments
We thank someone for insightful discussions.

\appendix

\section{Data}
%
We use XX millions of articles from the Web of Science from the years 1991-2015.
We take as text the title with abstract.
We employ the following pre-processing steps:
\begin{itemize}
 \item ...
\end{itemize}

\section{Limitation of 2D-projection}
\label{sec.viz.2d.limit}
%

ADD: Figure showing the correlation between distances from original space and projected 2D space.

%
% \begin{figure}[bt]
% \centering
% \includegraphics[width=0.99\columnwidth]{path_to_figure_and_name}
% \caption{
% captiontext
% }
% \label{fig.give_a_label}
% \end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Appendix %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliography{references}


\end{document}